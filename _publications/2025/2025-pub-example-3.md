---
id:             "2025-3_shi_mitigating"
title:          "Mitigating Reasoning Hallucination Through Multi-Agent Collaborative Filtering"
date:           2025-03-05 00:01:00 +0800
selected:       true
abbr:           'ESWA 2025'
label:          ' <span class="badge badge-pill badge-custom badge-primary">TOP</span> <span class="badge badge-pill badge-custom badge-primary">SCI Q1</span> <span class="badge badge-pill badge-custom badge-primary">IF = 7.5</span> <span class="badge badge-pill badge-custom badge-primary">CCF-C</span> <span class="badge badge-pill badge-custom badge-primary">EI-Indexed Journal</span> '
pub_pre:        ' <span class="badge badge-pill badge-custom badge-secondary">Journal</span> '
pub:            "Expert Systems with Applications"
pub_last:       ''
pub_date:       "2025"

abstract: >-
  Large language models (LLMs) have demonstrated excellent performance in various natural language tasks. However, in practical applications, LLMs frequently exhibit hallucinations, generating content that deviates from instructions or facts, especially in complex reasoning tasks. Existing research has simulated real human behavior by utilizing multi-agent debate, voting, and review, enhancing the model’s reasoning capabilities. However, simple multi-agent systems have not accomplished the progressive verification of all reasoning steps. Additionally, the issues of unstable response quality and the continuous learning ability of agents have not been addressed. Therefore, in this work, we propose a Multi-agent Collaborative Filtering framework (MCF) in the form of cross-examination among agents. This aims to cross-verify each step while filtering and selecting the highest-quality responses from the response space. Additionally, to enable agents to achieve continuous learning capabilities, this paper proposes methods for the automated construction and efficient retrieval of the experience repository. Extensive experiments on ten reasoning datasets of three types (Arithmetic, Commonsense, and Symbolic) indicate that MCF can enhance the diversity of large language models, overcome hallucinations, and filter out effective responses in a rich response space. Moreover, the improvement of agents’ reasoning capabilities through the experience repository is also verified. Compared to the state-of-the-art, the method proposed in this paper shows superior performance.

cover:          assets/images/covers/2025-3_shi_mitigating.jpg
authors:
  - Jinxin Shi
  - Jiabao Zhao
  - Xingjiao Wu
  - Ruyi Xu
  - Yuan-Hao Jiang
  - Liang He
PDF:          assets/PDF/2025-3_shi_mitigating.pdf
HTML:         https://doi.org/10.1016/j.eswa.2024.125723
CODE_OR_DATASET:   #
BIB:
  "@article{2025-3_shi_mitigating,</br>	title = {Mitigating Reasoning Hallucination Through Multi-Agent Collaborative Filtering},</br>	volume = {263},</br>	issn = {0957-4174},</br>	doi = {10.1016/j.eswa.2024.125723},</br>	language = {en-US},</br>	number = {2025},</br>	journal = {Expert Systems with Applications},</br>	author = {Shi, Jinxin and Zhao, Jiabao and Wu, Xingjiao and Xu, Ruyi and Jiang, Yuan-Hao and He, Liang},</br>	month = mar,</br>	year = {2025},</br>	pages = {125723},</br>}"
---
